In this lab, we explored the implementation of various deep learning architectures using the PyTorch library. We focused on three main tasks: building Auto-encoders (AE) and Variational Auto-encoders (VAE) for image reconstruction, and Generative Adversarial Networks (GANs) for generating abstract art.

For the AE and VAE tasks, we trained models on the MNIST dataset to reconstruct handwritten digits. We experimented with different architectures and hyperparameters to achieve optimal performance. Through evaluation metrics such as loss functions and KL divergence, we gained insights into the effectiveness of each model. Visualizing the latent spaces of the models provided further understanding of their representation capabilities.

Moving on to GANs, we utilized the Abstract Art Gallery dataset to train a GAN model for generating abstract art images. We defined generator and discriminator networks, and carefully designed loss functions to train the model effectively. By plotting loss curves and evaluating the quality of generated images, we assessed the performance of the GAN model.

Overall, this lab provided valuable hands-on experience with deep learning techniques and the PyTorch library. Through experimentation and analysis, we gained insights into model architectures, hyperparameters tuning, and model evaluation. This knowledge can be further applied to tackle real-world problems in various domains using deep learning methodologies.


[My LinkedIn Profile](https://www.linkedin.com/in/ziad-ben-saada-850219226/)
