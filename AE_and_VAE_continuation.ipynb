{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BakrAsskali/AE-VAE-GANs/blob/main/AE_and_VAE_continuation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eyXPqzC-I7V"
      },
      "outputs": [],
      "source": [
        "import torch;\n",
        "torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upyntcgP-OMk"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZeuwr7w-QeT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(784, 512)\n",
        "        self.linear2 = nn.Linear(512, latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        return self.linear2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYHTUkU0-VOX"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(latent_dims, 512)\n",
        "        self.linear2 = nn.Linear(512, 784)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.relu(self.linear1(z))\n",
        "        z = torch.sigmoid(self.linear2(z))\n",
        "        return z.reshape((-1, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7laOMQhn-ZMd"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Encoder(latent_dims)\n",
        "        self.decoder = Decoder(latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRLOr1Sa-b3x"
      },
      "outputs": [],
      "source": [
        "def train(autoencoder, data, epochs=20):\n",
        "    opt = torch.optim.Adam(autoencoder.parameters())\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in data:\n",
        "            x = x.to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat = autoencoder(x)\n",
        "            loss = ((x - x_hat)**2).sum()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL8LtTlA-f21"
      },
      "outputs": [],
      "source": [
        "# use grid search to find the best hyperparameters for the model\n",
        "grid_search = {\n",
        "    \"learning_rate\": [0.001, 0.01, 0.1],\n",
        "    \"batch_size\": [32, 64, 128],\n",
        "    \"epochs\": [10, 20, 30]\n",
        "}\n",
        "# create a list of hyperparameters\n",
        "hyperparameters = list(ParameterGrid(grid_search))\n",
        "# create a list of all possible combinations of hyperparameters\n",
        "combinations = list(itertools.product(hyperparameters, repeat = 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6_5Zph2-0Mh",
        "outputId": "21b45b34-e27e-4cc4-b285-1b02bbfa4027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, loss: 0.05591150215153755\n",
            "Epoch 2, loss: 0.04717671284988237\n",
            "Epoch 3, loss: 0.04539329800873931\n",
            "Epoch 4, loss: 0.04446853827565972\n",
            "Epoch 5, loss: 0.04380475542247931\n",
            "Epoch 6, loss: 0.0432480101678163\n",
            "Epoch 7, loss: 0.042810471120800796\n",
            "Epoch 8, loss: 0.042416814881474224\n",
            "Epoch 9, loss: 0.04205711309843734\n",
            "Epoch 10, loss: 0.041730828726215405\n",
            "Epoch 1, loss: 0.05012139605719652\n",
            "Epoch 2, loss: 0.045064932128577345\n",
            "Epoch 3, loss: 0.0439535023164012\n",
            "Epoch 4, loss: 0.04325635404760904\n",
            "Epoch 5, loss: 0.04279063554651447\n",
            "Epoch 6, loss: 0.042420870340518606\n",
            "Epoch 7, loss: 0.04210429635446972\n",
            "Epoch 8, loss: 0.041886765636932624\n",
            "Epoch 9, loss: 0.04172585887123527\n",
            "Epoch 10, loss: 0.041592236227000444\n",
            "Epoch 1, loss: 0.11226055998283663\n",
            "Epoch 2, loss: 0.11199256120078853\n",
            "Epoch 3, loss: 0.1119937520227961\n",
            "Epoch 4, loss: 0.11199099287740204\n",
            "Epoch 5, loss: 0.1119877586740929\n",
            "Epoch 6, loss: 0.1119933707722977\n",
            "Epoch 7, loss: 0.11199420739783407\n",
            "Epoch 8, loss: 0.11199301722715659\n",
            "Epoch 9, loss: 0.11198970654816516\n",
            "Epoch 10, loss: 0.11198938156623067\n",
            "Epoch 1, loss: 0.05573591825041944\n",
            "Epoch 2, loss: 0.047328912110915826\n",
            "Epoch 3, loss: 0.045513549895047634\n",
            "Epoch 4, loss: 0.04455861413497915\n",
            "Epoch 5, loss: 0.04388164913158681\n",
            "Epoch 6, loss: 0.0433487656162873\n",
            "Epoch 7, loss: 0.042886309468669934\n",
            "Epoch 8, loss: 0.042475672990782684\n",
            "Epoch 9, loss: 0.04213472014900718\n",
            "Epoch 10, loss: 0.04178660900703371\n",
            "Epoch 11, loss: 0.041484038895571916\n",
            "Epoch 12, loss: 0.041216330146039724\n",
            "Epoch 13, loss: 0.04097746273697312\n",
            "Epoch 14, loss: 0.04075992310733429\n",
            "Epoch 15, loss: 0.04057434271933682\n",
            "Epoch 16, loss: 0.04035983533302604\n",
            "Epoch 17, loss: 0.040193714709805525\n",
            "Epoch 18, loss: 0.040024033646339545\n",
            "Epoch 19, loss: 0.03986240535783869\n",
            "Epoch 20, loss: 0.03972200255022883\n",
            "Epoch 1, loss: 0.0493107079061618\n",
            "Epoch 2, loss: 0.04455676158544605\n",
            "Epoch 3, loss: 0.04350615511221418\n",
            "Epoch 4, loss: 0.04275007344194567\n",
            "Epoch 5, loss: 0.04232962768691689\n",
            "Epoch 6, loss: 0.0419453208618708\n",
            "Epoch 7, loss: 0.0416313764144744\n",
            "Epoch 8, loss: 0.041523078539923056\n",
            "Epoch 9, loss: 0.0412257019438342\n",
            "Epoch 10, loss: 0.04109074385848635\n",
            "Epoch 11, loss: 0.04097476267992561\n",
            "Epoch 12, loss: 0.04083679901606747\n",
            "Epoch 13, loss: 0.04073180595059385\n",
            "Epoch 14, loss: 0.04066617749551974\n",
            "Epoch 15, loss: 0.0404487586637804\n",
            "Epoch 16, loss: 0.040456190228716396\n",
            "Epoch 17, loss: 0.040397183782955225\n",
            "Epoch 18, loss: 0.04029833086962893\n",
            "Epoch 19, loss: 0.04025310929268916\n",
            "Epoch 20, loss: 0.0402382860607557\n",
            "Epoch 1, loss: 0.11295834761946949\n",
            "Epoch 2, loss: 0.11270629640009358\n",
            "Epoch 3, loss: 0.11270662227164963\n",
            "Epoch 4, loss: 0.11271066326640054\n",
            "Epoch 5, loss: 0.11270386724075529\n",
            "Epoch 6, loss: 0.11270680562900837\n",
            "Epoch 7, loss: 0.11270390708309247\n",
            "Epoch 8, loss: 0.11270325346542065\n",
            "Epoch 9, loss: 0.11270632523336391\n",
            "Epoch 10, loss: 0.11270680178457232\n",
            "Epoch 11, loss: 0.11270107357486733\n",
            "Epoch 12, loss: 0.11270451015119613\n",
            "Epoch 13, loss: 0.11270729731966946\n",
            "Epoch 14, loss: 0.11270700007486445\n",
            "Epoch 15, loss: 0.11270237116734864\n",
            "Epoch 16, loss: 0.11270759805941633\n",
            "Epoch 17, loss: 0.11270628146716018\n",
            "Epoch 18, loss: 0.11270669082016833\n",
            "Epoch 19, loss: 0.11270568213228986\n",
            "Epoch 20, loss: 0.11270928209715052\n",
            "Epoch 1, loss: 0.056416716791991235\n",
            "Epoch 2, loss: 0.048548062830400876\n",
            "Epoch 3, loss: 0.0463370496291977\n",
            "Epoch 4, loss: 0.04495109188785431\n",
            "Epoch 5, loss: 0.044062281182325726\n",
            "Epoch 6, loss: 0.04341332909108987\n",
            "Epoch 7, loss: 0.042886134816893635\n",
            "Epoch 8, loss: 0.042488187472067916\n",
            "Epoch 9, loss: 0.04215528743702974\n",
            "Epoch 10, loss: 0.04183096156668053\n",
            "Epoch 11, loss: 0.04159403146743012\n",
            "Epoch 12, loss: 0.04133036291834388\n",
            "Epoch 13, loss: 0.041119700532033246\n",
            "Epoch 14, loss: 0.040903200584052724\n",
            "Epoch 15, loss: 0.04070604371744941\n",
            "Epoch 16, loss: 0.04052847735027769\n",
            "Epoch 17, loss: 0.040349584970392906\n",
            "Epoch 18, loss: 0.040202582521098\n",
            "Epoch 19, loss: 0.04004231891207603\n",
            "Epoch 20, loss: 0.03992337235477942\n",
            "Epoch 21, loss: 0.03977279094999025\n",
            "Epoch 22, loss: 0.03966264698360521\n",
            "Epoch 23, loss: 0.03954841340306217\n",
            "Epoch 24, loss: 0.03944750205635516\n",
            "Epoch 25, loss: 0.03931494761727004\n",
            "Epoch 26, loss: 0.03920288870869669\n",
            "Epoch 27, loss: 0.03915212860207822\n",
            "Epoch 28, loss: 0.0390233266264645\n",
            "Epoch 29, loss: 0.03893964892543201\n",
            "Epoch 30, loss: 0.0388326422968653\n",
            "Epoch 1, loss: 0.049672842565884216\n",
            "Epoch 2, loss: 0.04513515077674313\n",
            "Epoch 3, loss: 0.04382721630971569\n",
            "Epoch 4, loss: 0.04320401290078153\n",
            "Epoch 5, loss: 0.04265385179885669\n",
            "Epoch 6, loss: 0.04241323665674053\n",
            "Epoch 7, loss: 0.042146856024829565\n",
            "Epoch 8, loss: 0.0418767005777054\n",
            "Epoch 9, loss: 0.04178568093316642\n",
            "Epoch 10, loss: 0.04161005641129225\n",
            "Epoch 11, loss: 0.041449190814421374\n",
            "Epoch 12, loss: 0.04133202902861496\n",
            "Epoch 13, loss: 0.0411845718158969\n",
            "Epoch 14, loss: 0.0410844752275105\n",
            "Epoch 15, loss: 0.04108353455596641\n",
            "Epoch 16, loss: 0.04099681711336697\n",
            "Epoch 17, loss: 0.04093719805195642\n",
            "Epoch 18, loss: 0.040844610369980716\n",
            "Epoch 19, loss: 0.04074476506791389\n",
            "Epoch 20, loss: 0.04068565510038628\n",
            "Epoch 21, loss: 0.04069841621336398\n",
            "Epoch 22, loss: 0.04062212612043058\n",
            "Epoch 23, loss: 0.040608222367984656\n",
            "Epoch 24, loss: 0.040530515648027475\n",
            "Epoch 25, loss: 0.04043168509438602\n",
            "Epoch 26, loss: 0.04044718902184765\n",
            "Epoch 27, loss: 0.040365367397062306\n",
            "Epoch 28, loss: 0.040322673298529725\n",
            "Epoch 29, loss: 0.04041192245318183\n",
            "Epoch 30, loss: 0.040308713507868334\n",
            "Epoch 1, loss: 0.11443576949046873\n",
            "Epoch 2, loss: 0.11418564379342329\n",
            "Epoch 3, loss: 0.11418740568893042\n",
            "Epoch 4, loss: 0.11418605880188282\n",
            "Epoch 5, loss: 0.11419006827861261\n",
            "Epoch 6, loss: 0.11418741731755515\n",
            "Epoch 7, loss: 0.11418852373671684\n",
            "Epoch 8, loss: 0.1141859017677907\n",
            "Epoch 9, loss: 0.11418771070203801\n",
            "Epoch 10, loss: 0.11418631931802611\n",
            "Epoch 11, loss: 0.11418692762854257\n",
            "Epoch 12, loss: 0.11418772995599043\n",
            "Epoch 13, loss: 0.11418726095067921\n",
            "Epoch 14, loss: 0.11418546605974372\n",
            "Epoch 15, loss: 0.11419031606999033\n",
            "Epoch 16, loss: 0.11418724217330978\n",
            "Epoch 17, loss: 0.11419027146182335\n",
            "Epoch 18, loss: 0.11419102605154265\n",
            "Epoch 19, loss: 0.11418856613671602\n",
            "Epoch 20, loss: 0.11418669079857341\n",
            "Epoch 21, loss: 0.11418973297071355\n",
            "Epoch 22, loss: 0.1141871999162855\n",
            "Epoch 23, loss: 0.11418881227593941\n",
            "Epoch 24, loss: 0.11418855118789653\n",
            "Epoch 25, loss: 0.11418714212265604\n",
            "Epoch 26, loss: 0.11418476336991101\n",
            "Epoch 27, loss: 0.11419022218314315\n",
            "Epoch 28, loss: 0.11418873311550633\n",
            "Epoch 29, loss: 0.11419038552401671\n",
            "Epoch 30, loss: 0.11418723772520195\n",
            "Epoch 1, loss: 0.05566472568904667\n",
            "Epoch 2, loss: 0.047305529901404374\n",
            "Epoch 3, loss: 0.04544376320580938\n",
            "Epoch 4, loss: 0.044391638768125956\n",
            "Epoch 5, loss: 0.043612704483240144\n",
            "Epoch 6, loss: 0.04303339469248552\n",
            "Epoch 7, loss: 0.042534773116871746\n",
            "Epoch 8, loss: 0.04212338099283958\n",
            "Epoch 9, loss: 0.04177976117681847\n",
            "Epoch 10, loss: 0.041451673184249443\n",
            "Epoch 1, loss: 0.04995386057825231\n",
            "Epoch 2, loss: 0.04470475800414838\n",
            "Epoch 3, loss: 0.04351884517461252\n",
            "Epoch 4, loss: 0.04281611014594401\n",
            "Epoch 5, loss: 0.042347106470990534\n",
            "Epoch 6, loss: 0.04202003881875386\n",
            "Epoch 7, loss: 0.041672552238776486\n",
            "Epoch 8, loss: 0.04156127767458653\n",
            "Epoch 9, loss: 0.04137299850837254\n",
            "Epoch 10, loss: 0.04120453311277351\n",
            "Epoch 1, loss: 0.11266924955570368\n",
            "Epoch 2, loss: 0.11240142602910365\n",
            "Epoch 3, loss: 0.11240670123079946\n",
            "Epoch 4, loss: 0.11240179652471279\n",
            "Epoch 5, loss: 0.11240196019919442\n",
            "Epoch 6, loss: 0.11240371739241614\n",
            "Epoch 7, loss: 0.11240399187244078\n",
            "Epoch 8, loss: 0.11240475996534453\n",
            "Epoch 9, loss: 0.1124022211760346\n",
            "Epoch 10, loss: 0.11240034412219325\n",
            "Epoch 1, loss: 0.05689586324096997\n",
            "Epoch 2, loss: 0.048059947478936424\n",
            "Epoch 3, loss: 0.04626620791232916\n",
            "Epoch 4, loss: 0.04521964012242075\n",
            "Epoch 5, loss: 0.044369846860419455\n",
            "Epoch 6, loss: 0.0436579289196778\n",
            "Epoch 7, loss: 0.04308904758267311\n",
            "Epoch 8, loss: 0.042615158042546786\n",
            "Epoch 9, loss: 0.04221607338803918\n",
            "Epoch 10, loss: 0.04186320045927186\n",
            "Epoch 11, loss: 0.04159806634603279\n",
            "Epoch 12, loss: 0.041314898046857514\n",
            "Epoch 13, loss: 0.04112005984382843\n",
            "Epoch 14, loss: 0.04086395207721033\n",
            "Epoch 15, loss: 0.04069436671160686\n",
            "Epoch 16, loss: 0.04049114010004855\n",
            "Epoch 17, loss: 0.040330432268030354\n",
            "Epoch 18, loss: 0.04018313183522682\n",
            "Epoch 19, loss: 0.04001768248707755\n",
            "Epoch 20, loss: 0.039878330751459225\n",
            "Epoch 1, loss: 0.05017007532309113\n",
            "Epoch 2, loss: 0.04554555847097053\n",
            "Epoch 3, loss: 0.04419181438714965\n",
            "Epoch 4, loss: 0.04343693029842397\n",
            "Epoch 5, loss: 0.04290411959706085\n",
            "Epoch 6, loss: 0.042587419928136916\n",
            "Epoch 7, loss: 0.04229636486373477\n",
            "Epoch 8, loss: 0.042064748799750036\n",
            "Epoch 9, loss: 0.041846567117519724\n",
            "Epoch 10, loss: 0.04181561955034351\n",
            "Epoch 11, loss: 0.04161055592585729\n",
            "Epoch 12, loss: 0.041453270094671736\n",
            "Epoch 13, loss: 0.04136999505065651\n",
            "Epoch 14, loss: 0.04125327298413716\n",
            "Epoch 15, loss: 0.04127244105630084\n",
            "Epoch 16, loss: 0.04111327093515569\n",
            "Epoch 17, loss: 0.04101601972985369\n",
            "Epoch 18, loss: 0.041026517621743905\n",
            "Epoch 19, loss: 0.040869888315386356\n",
            "Epoch 20, loss: 0.04089931188933631\n",
            "Epoch 1, loss: 0.11257903727450605\n",
            "Epoch 2, loss: 0.11232842037926859\n",
            "Epoch 3, loss: 0.11233052557338276\n",
            "Epoch 4, loss: 0.11232739841061107\n",
            "Epoch 5, loss: 0.11233037371815903\n",
            "Epoch 6, loss: 0.11232656234108818\n",
            "Epoch 7, loss: 0.11232647631786016\n",
            "Epoch 8, loss: 0.11232639912730341\n",
            "Epoch 9, loss: 0.11232738779869669\n",
            "Epoch 10, loss: 0.1123291868517902\n",
            "Epoch 11, loss: 0.11232943152949246\n",
            "Epoch 12, loss: 0.11232782309370509\n",
            "Epoch 13, loss: 0.11232922488311206\n",
            "Epoch 14, loss: 0.11232639668084411\n",
            "Epoch 15, loss: 0.11232992601610704\n",
            "Epoch 16, loss: 0.1123297304899962\n",
            "Epoch 17, loss: 0.11232760408793939\n",
            "Epoch 18, loss: 0.11232714693365829\n",
            "Epoch 19, loss: 0.11232596872521362\n",
            "Epoch 20, loss: 0.1123295263218473\n",
            "Epoch 1, loss: 0.05560755758270272\n",
            "Epoch 2, loss: 0.04810601423607706\n",
            "Epoch 3, loss: 0.04625733958473846\n",
            "Epoch 4, loss: 0.04521380267989661\n",
            "Epoch 5, loss: 0.04442508652933371\n",
            "Epoch 6, loss: 0.04382955241622701\n",
            "Epoch 7, loss: 0.043306382130712334\n"
          ]
        }
      ],
      "source": [
        "# create a list to store the loss values\n",
        "loss_values = []\n",
        "data = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.MNIST('./data',\n",
        "               transform=torchvision.transforms.ToTensor(),\n",
        "               download=True),\n",
        "        batch_size=128,\n",
        "        shuffle=True)\n",
        "# loop through all the combinations of hyperparameters\n",
        "for combination in combinations:\n",
        "    # create a model\n",
        "    model = Autoencoder(2).to(device)\n",
        "    # create a loss function\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    # create an optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = combination[0][\"learning_rate\"])\n",
        "    # loop through the number of epochs\n",
        "    for epoch in range(combination[0][\"epochs\"]):\n",
        "        # create a list to store the losses\n",
        "        losses = []\n",
        "        # loop through the data loader\n",
        "        for batch_features, _ in data:\n",
        "            # reshape the data\n",
        "            batch_features = batch_features.view(-1, 28 * 28)\n",
        "            # set the gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass\n",
        "            outputs = model(batch_features)\n",
        "            # Reshape the outputs tensor to match the shape of the batch_features tensor\n",
        "            outputs = outputs.view(-1, 784)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, batch_features)\n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "            # update the weights\n",
        "            optimizer.step()\n",
        "            # append the loss\n",
        "            losses.append(loss.item())\n",
        "        # print the loss\n",
        "        print(f\"Epoch {epoch + 1}, loss: {np.mean(losses)}\")\n",
        "    # append the loss values\n",
        "    loss_values.append(np.mean(losses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrYUt2oS-58V"
      },
      "outputs": [],
      "source": [
        "# find the best hyperparameters\n",
        "best_hyperparameters = hyperparameters[np.argmin(loss_values)]\n",
        "# print the best hyperparameters\n",
        "print(best_hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSbQ5svU-elN"
      },
      "outputs": [],
      "source": [
        "latent_dims = 2\n",
        "autoencoder = Autoencoder(latent_dims).to(device) # GPU\n",
        "\n",
        "data = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.MNIST('./data',\n",
        "               transform=torchvision.transforms.ToTensor(),\n",
        "               download=True),\n",
        "        batch_size=128,\n",
        "        shuffle=True)\n",
        "\n",
        "autoencoder = train(autoencoder, data, best_hyperparameters[\"epochs\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyMm04k4fSHTCsvWmOJ5Jd/T",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}